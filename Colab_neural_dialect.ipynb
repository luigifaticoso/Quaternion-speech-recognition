{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_ph.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "7K7WgbtQIo-U"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo3FF-R9ne16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/jameslyons/python_speech_features.git\n",
        "!sudo apt-get install libsndfile-dev\n",
        "!git clone https://github.com/JoergFranke/phoneme_recognition.git && cd phoneme_recognition && pip install -r requirements.txt\n",
        "!unzip \"./drive/My Drive/COLAB Neural/files_for_neural_Lom100_final.zip\"\n",
        "!unzip \"./drive/My Drive/COLAB Neural/file_train_colab_100_ep_15_b_3.zip\"\n",
        "\n",
        "!python working_example_Lom.py \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO0ijaCMnsDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install libsndfile-dev\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeRgQ-wTnxd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/JoergFranke/phoneme_recognition.git && cd phoneme_recognition && pip install -r requirements.txt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K7WgbtQIo-U",
        "colab_type": "text"
      },
      "source": [
        "# FIRST CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfPoq6qmv0lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"./drive/My Drive/COLAB Neural/files_for_neural_Lom250_final.zip\"\n",
        "!unzip \"./drive/My Drive/COLAB Neural/file_train_colab250.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vvqpiUWdUav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#####################################################\n",
        "#                    FIRST CODE                     #\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kovGKiNN5r2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_list = {'DR1': \"1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR2': \"0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR3': \"0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR4': \"0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR5': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR6': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0\", \n",
        "            'DR7': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0\", \n",
        "            'DR8': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1\" \n",
        "            }\n",
        "dirlist = ['DR1', 'DR2', 'DR3', 'DR4', 'DR5', 'DR6', 'DR7', 'DR8']\n",
        "\n",
        "# creazione dei quaternioni appesi alla lista final_quat\n",
        "def make_quaternion(mat):\n",
        "\t#print(mat.shape)\n",
        "\tres = []\n",
        "\tfor row in range(len(mat)):\n",
        "\t\tfor j in range(41):\n",
        "\t\t\tquat = [0,mat[row][j],mat[row][j+41],mat[row][j+82]]\n",
        "\t\t\tres.append(quat)\n",
        "\treturn res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ####################################\n",
        "    # pre process parameters    \n",
        "\t\n",
        "    # Mel-Frequency Cepstrum Coefficients, default 12\n",
        "    numcep=40 #40\n",
        "\t\n",
        "    # the number of filters in the filterbank, default 26\n",
        "    numfilt = 40 #40\n",
        "\n",
        "\t# the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
        "    winlen = 0.025\n",
        "\t\n",
        "    # the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
        "    winstep = 0.01\n",
        "\t\n",
        "    # use  first or first+second order derivation\n",
        "    grad = 2\n",
        "\n",
        "\t#number of elements for each set of quaternions\n",
        "    N_SPLIT = 300\n",
        "\n",
        "    dir_name = \"./drive/My Drive/COLAB Neural/Quaternion_\" + str(N_SPLIT) + \"_Lamush\"\n",
        "    tree = \"./drive/My Drive/COLAB Neural/\" + dir_name\n",
        "#     tree = \"/home/franci/Desktop/NN/Quaternion-speech-recognition/\" + dir_name\n",
        "    if os.path.isdir(tree):\n",
        "        shutil.rmtree(tree)\n",
        "    \n",
        "    os.makedirs(dir_name)\n",
        "    path_to_quats = os.path.abspath(dir_name)\n",
        "    \n",
        "    path_to_prep_files = os.path.abspath(\"./drive/My Drive/COLAB Neural/preprocessed_files_with_dict/\")\n",
        "    dir = os.listdir(path_to_prep_files)\n",
        "\n",
        "    for path_dict in dir:\n",
        "        print(\"Analizzo la cartella \" + str(path_dict))\n",
        "        dir_dict = os.listdir(path_to_prep_files + \"/\" + str(path_dict))\n",
        "        for file in dir_dict:\n",
        "            if file.split(\".\")[1] == \"WAV\":\n",
        "                p = path_to_prep_files + \"/\" + str(path_dict) + \"/\" + file\n",
        "                f = Sndfile(p, 'r')\n",
        "                frames = f.nframes\n",
        "                samplerate = f.samplerate\n",
        "                data = f.read_frames(frames)\n",
        "                data = np.asarray(data)\n",
        "                #print(data.shape)\n",
        "                #calc mfcc\n",
        "                feat_raw,energy = sf.fbank(data, samplerate,winlen,winstep, nfilt=numfilt)\n",
        "                feat = np.log(feat_raw)\n",
        "                feat = sf.dct(feat, type=2, axis=1, norm='ortho')[:,:numcep]\n",
        "                feat = sf.lifter(feat,L=22)\n",
        "                feat = np.asarray(feat)\n",
        "                #calc log energy\n",
        "                log_energy = np.log(energy) #np.log( np.sum(feat_raw**2, axis=1) )\n",
        "                log_energy = log_energy.reshape([log_energy.shape[0],1])\n",
        "                mat = ( feat - np.mean(feat, axis=0) ) / (0.5 * np.std(feat, axis=0))\n",
        "                mat = np.concatenate((mat, log_energy), axis=1)\n",
        "                #calc first order derivatives\n",
        "                if grad >= 1:\n",
        "                    gradf = np.gradient(mat)[0]\n",
        "                    mat = np.concatenate((mat, gradf), axis=1)\n",
        "                #calc second order derivatives\n",
        "                if grad == 2:\n",
        "                    grad2f = np.gradient(gradf)[0]\n",
        "                    mat = np.concatenate((mat, grad2f), axis=1)\n",
        "\n",
        "                file_to_create = path_to_quats + \"/\" + file.split(\".\")[0] + \"_processed.data\"\n",
        "                ff = open(file_to_create, \"w\")\n",
        "                n = 1\n",
        "                item = 0\n",
        "                print(\"Creo il quaternione\")\n",
        "                # quats_dict = make_quaternion(mat)\n",
        "                quats = make_quaternion(mat)\n",
        "                print('Appendo la classe del dialetto al quaternione')\n",
        "                dictionary ='\\t' + dict_list[path_dict]\n",
        "                # quats_dict.append(dictionary)\n",
        "                quats_length = len(quats)\n",
        "\n",
        "                while (item < quats_length):\n",
        "                    if item == N_SPLIT * n:\n",
        "                        ff.write(dictionary)\n",
        "                        ff.write(\"\\n\")\n",
        "                        n = n + 1\n",
        "                    quat = quats[item]\n",
        "                    for i in range(len(quat)):\n",
        "                        if i == 3:\n",
        "                            ff.write(str(quat[i]) + \" \")\n",
        "                        else:\n",
        "                            ff.write(str(quat[i]) + \",\")\n",
        "                    item = item + 1\n",
        "                x = int((n*N_SPLIT) - quats_length)\n",
        "                for i in range(x):\n",
        "                    if i < x-1:\n",
        "                        ff.write(\"0,0,0,0 \")\n",
        "                    else:\n",
        "                        ff.write(\"0,0,0,0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgSF_hezX6_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip quaternion_400_3.zip /content/drive/My\\ Drive/COLAB\\ Neural/Quaternion_400_Lamush\n",
        "#!unzip preprocessed_files_with_dict.zip -d /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1gFx6UpgcGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################################################\n",
        "#                    SECOND CODE                    #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rycWaPTL0af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from scikits.audiolab import Sndfile\n",
        "import python_speech_features as sf\n",
        "\n",
        "dict_list = {'DR1': \"1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR2': \"0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR3': \"0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR4': \"0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR5': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR6': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0\", \n",
        "            'DR7': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0\", \n",
        "            'DR8': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1\" \n",
        "            }\n",
        "dirlist = ['DR1', 'DR2', 'DR3', 'DR4', 'DR5', 'DR6', 'DR7', 'DR8']\n",
        "\n",
        "# creazione dei quaternioni appesi alla lista final_quat\n",
        "def make_quaternion(mat):\n",
        "\t#print(mat.shape)\n",
        "\tres = []\n",
        "\tfor row in range(len(mat)):\n",
        "\t\tfor j in range(41):\n",
        "\t\t\tquat = [0,mat[row][j],mat[row][j+41],mat[row][j+82]]\n",
        "\t\t\tres.append(quat)\n",
        "\treturn res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ####################################\n",
        "    # pre process parameters    \n",
        "\t\n",
        "    # Mel-Frequency Cepstrum Coefficients, default 12\n",
        "    numcep=40 #40\n",
        "\t\n",
        "    # the number of filters in the filterbank, default 26\n",
        "    numfilt = 40 #40\n",
        "\n",
        "\t# the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
        "    winlen = 0.025\n",
        "\t\n",
        "    # the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
        "    winstep = 0.01\n",
        "\t\n",
        "    # use  first or first+second order derivation\n",
        "    grad = 2\n",
        "\n",
        "\t#number of elements for each set of quaternions\n",
        "    N_SPLIT = 400\n",
        "    #./drive/My Drive/COLAB Neural/\n",
        "    dir_name = \"Quaternion_\" + str(N_SPLIT) + \"_Lamush\"\n",
        "    tree = dir_name\n",
        "    \n",
        "    #tree = \"/home/franci/Desktop/NN/Quaternion-speech-recognition/\" + dir_name\n",
        "    \n",
        "    if os.path.isdir(tree):\n",
        "        shutil.rmtree(tree)\n",
        "    os.makedirs(dir_name)\n",
        "    path_to_quats = os.path.abspath(dir_name)\n",
        "\n",
        "    train_file = os.path.join(path_to_quats,\"TRAIN\" + \"_processed.data\")\n",
        "    dev_file = os.path.join(path_to_quats,\"DEV\" + \"_processed.data\")\n",
        "    test_file = os.path.join(path_to_quats,\"TEST\" + \"_processed.data\")\n",
        "\n",
        "    if os.path.isfile(train_file):\n",
        "        os.remove(train_file)\n",
        "    if os.path.isfile(dev_file):\n",
        "        os.remove(dev_file)\n",
        "    if os.path.isfile(test_file):\n",
        "        os.remove(test_file)\n",
        "    \n",
        "    #count = 0 \n",
        "    \n",
        "    path_to_prep_files = os.path.abspath(\"preprocessed_files_with_dict/\")\n",
        "    dir = os.listdir(path_to_prep_files)\n",
        "    \n",
        "    ff = open(train_file, \"w\")\n",
        "    fd = open(dev_file, \"w\")\n",
        "    ft = open(test_file, \"w\")\n",
        "         \n",
        "    for path_dict in dir:\n",
        "        print(\"Analizzo la cartella \" + str(path_dict))\n",
        "        # tutti i file nella cartella\n",
        "        dir_dict = os.listdir(path_to_prep_files + \"/\" + str(path_dict))\n",
        "        count = 0\n",
        "        for file in dir_dict:\n",
        "            if file.split(\".\")[1] == \"WAV\":\n",
        "                p = path_to_prep_files + \"/\" + str(path_dict) + \"/\" + file\n",
        "                f = Sndfile(p, 'r')\n",
        "                frames = f.nframes\n",
        "                samplerate = f.samplerate\n",
        "                data = f.read_frames(frames)\n",
        "                data = np.asarray(data)\n",
        "                #print(data.shape)\n",
        "                #calc mfcc\n",
        "                feat_raw,energy = sf.fbank(data, samplerate,winlen,winstep, nfilt=numfilt)\n",
        "                feat = np.log(feat_raw)\n",
        "                feat = sf.dct(feat, type=2, axis=1, norm='ortho')[:,:numcep]\n",
        "                feat = sf.lifter(feat,L=22)\n",
        "                feat = np.asarray(feat)\n",
        "                #calc log energy\n",
        "                log_energy = np.log(energy) #np.log( np.sum(feat_raw**2, axis=1) )\n",
        "                log_energy = log_energy.reshape([log_energy.shape[0],1])\n",
        "                mat = ( feat - np.mean(feat, axis=0) ) / (0.5 * np.std(feat, axis=0))\n",
        "                mat = np.concatenate((mat, log_energy), axis=1)\n",
        "                #calc first order derivatives\n",
        "                if grad >= 1:\n",
        "                    gradf = np.gradient(mat)[0]\n",
        "                    mat = np.concatenate((mat, gradf), axis=1)\n",
        "                #calc second order derivatives\n",
        "                if grad == 2:\n",
        "                    grad2f = np.gradient(gradf)[0]\n",
        "                    mat = np.concatenate((mat, grad2f), axis=1)\n",
        "                \n",
        "                #file_to_create = path_to_quats + \"/\" + file.split(\".\")[0] + \"_processed.data\"\n",
        "                # ff = open(file_to_create, \"w\")\n",
        "\n",
        "                \"\"\"\n",
        "                ff = open(train_file, \"w\")\n",
        "                fd = open(dev_file, \"w\")\n",
        "                ft = open(test_file, \"w\")\n",
        "                \"\"\"\n",
        "                \n",
        "                n = 1\n",
        "                item = 0\n",
        "                print(\"Creo il quaternione\")\n",
        "                # quats_dict = make_quaternion(mat)\n",
        "                quats = make_quaternion(mat)\n",
        "                print('Appendo la classe del dialetto al quaternione')\n",
        "                dictionary ='\\t' + dict_list[path_dict]\n",
        "                \n",
        "                # quats_dict.append(dictionary)\n",
        "                len_dir = (len(dir_dict))/4\n",
        "                quats_length = len(quats)\n",
        "                count += 1\n",
        "                print('Quantita file nella cartella ' + path_dict + ': ' + str(len_dir) + ' '+ str(count))\n",
        "                if count > ((len_dir*90)/100):\n",
        "                  print(\"Creo DEV_FILE \"+ str(count))\n",
        "                  while (item < quats_length):\n",
        "                    if item == N_SPLIT * n:\n",
        "                        fd.write(dictionary)\n",
        "                        fd.write(\"\\n\")\n",
        "                        n = n + 1\n",
        "                    quat = quats[item]\n",
        "                    for i in range(len(quat)):\n",
        "                        if i == 3:\n",
        "                            fd.write(str(quat[i]) + \" \")\n",
        "                        else:\n",
        "                            fd.write(str(quat[i]) + \",\")\n",
        "                        item = item + 1\n",
        "                  x = int((n*N_SPLIT) - quats_length)\n",
        "                  for i in range(x):\n",
        "                      if i < x-1:\n",
        "                          fd.write(\"0,0,0,0 \")\n",
        "                      else:\n",
        "                          fd.write(\"0,0,0,0\")\n",
        "                elif count>((len_dir*70)/100):\n",
        "                  print(\"Creo TEST_FILE \" + str(count))\n",
        "                  while (item < quats_length):\n",
        "                        if item == N_SPLIT * n:\n",
        "                            ft.write(dictionary)\n",
        "                            ft.write(\"\\n\")\n",
        "                            n = n + 1\n",
        "                        quat = quats[item]\n",
        "                        for i in range(len(quat)):\n",
        "                            if i == 3:\n",
        "                                ft.write(str(quat[i]) + \" \")\n",
        "                            else:\n",
        "                                ft.write(str(quat[i]) + \",\")\n",
        "                        item = item + 1\n",
        "                  x = int((n*N_SPLIT) - quats_length)\n",
        "                  for i in range(x):\n",
        "                      if i < x-1:\n",
        "                          ft.write(\"0,0,0,0 \")\n",
        "                      else:\n",
        "                          ft.write(\"0,0,0,0\")\n",
        "                else:\n",
        "                  print(\"Creo TRAIN_FILE \"+ str(count))\n",
        "                  while (item < quats_length):\n",
        "                      if item == N_SPLIT * n:\n",
        "                          ff.write(dictionary)\n",
        "                          ff.write(\"\\n\")\n",
        "                          n = n + 1\n",
        "                      quat = quats[item]\n",
        "                      for i in range(len(quat)):\n",
        "                          if i == 3:\n",
        "                              ff.write(str(quat[i]) + \" \")\n",
        "                          else:\n",
        "                              ff.write(str(quat[i]) + \",\")\n",
        "                      item = item + 1\n",
        "                  x = int((n*N_SPLIT) - quats_length)\n",
        "                  for i in range(x):\n",
        "                      if i < x-1:\n",
        "                          ff.write(\"0,0,0,0 \")\n",
        "                      else:\n",
        "                          ff.write(\"0,0,0,0\")\n",
        "    #count = 0\n",
        "    ff.close()\n",
        "    ft.close()\n",
        "    fd.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLB6aKaHgjIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################################################\n",
        "#                    THIRD CODE                     #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZwkOXL_rHLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r Quaternion_250_Lamush/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYFIxkOKglzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from scikits.audiolab import Sndfile\n",
        "import python_speech_features as sf\n",
        "\n",
        "dict_list = {'DR1': \"1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR2': \"0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR3': \"0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR4': \"0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR5': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR6': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0\", \n",
        "            'DR7': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0\", \n",
        "            'DR8': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1\" \n",
        "            }\n",
        "dirlist = ['DR1', 'DR2', 'DR3', 'DR4', 'DR5', 'DR6', 'DR7', 'DR8']\n",
        "\n",
        "# creazione dei quaternioni appesi alla lista final_quat\n",
        "def make_quaternion(mat):\n",
        "\t#print(mat.shape)\n",
        "\tres = []\n",
        "\tfor row in range(len(mat)):\n",
        "\t\tfor j in range(41):\n",
        "\t\t\tquat = [0,mat[row][j],mat[row][j+41],mat[row][j+82]]\n",
        "\t\t\tres.append(quat)\n",
        "\treturn res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ####################################\n",
        "    # pre process parameters    \n",
        "\t\n",
        "    # Mel-Frequency Cepstrum Coefficients, default 12\n",
        "    numcep=40 #40\n",
        "\t\n",
        "    # the number of filters in the filterbank, default 26\n",
        "    numfilt = 40 #40\n",
        "\n",
        "\t# the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
        "    winlen = 0.025\n",
        "\t\n",
        "    # the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
        "    winstep = 0.01\n",
        "\t\n",
        "    # use  first or first+second order derivation\n",
        "    grad = 2\n",
        "\n",
        "\t#number of elements for each set of quaternions\n",
        "    N_SPLIT = 400\n",
        "    #./drive/My Drive/COLAB Neural/\n",
        "    #dir_name = \"Quaternion_\" + str(N_SPLIT) + \"_Lamush\"\n",
        "    dir_name = \"decoda\"\n",
        "    tree = dir_name\n",
        "    \n",
        "    #tree = \"/home/franci/Desktop/NN/Quaternion-speech-recognition/\" + dir_name\n",
        "    \n",
        "    if os.path.isdir(tree):\n",
        "        shutil.rmtree(tree)\n",
        "    os.makedirs(dir_name)\n",
        "    path_to_quats = os.path.abspath(dir_name)\n",
        "\n",
        "    train_file = os.path.join(path_to_quats,\"TRAIN_process\" + \".data\")\n",
        "    dev_file = os.path.join(path_to_quats,\"DEV_process\" + \".data\")\n",
        "    test_file = os.path.join(path_to_quats,\"TEST_process\" + \".data\")\n",
        "\n",
        "    if os.path.isfile(train_file):\n",
        "        os.remove(train_file)\n",
        "    if os.path.isfile(dev_file):\n",
        "        os.remove(dev_file)\n",
        "    if os.path.isfile(test_file):\n",
        "        os.remove(test_file)\n",
        "    \n",
        "    #count = 0 \n",
        "    path_to_prep_files = os.path.abspath(\"./drive/My Drive/COLAB Neural/preprocessed_files_with_dict/\")\n",
        "    \n",
        "#     path_to_prep_files = os.path.abspath(\"preprocessed_files_with_dict/\")\n",
        "    dir = os.listdir(path_to_prep_files)\n",
        "    \n",
        "    ff = open(train_file, \"w\")\n",
        "    fd = open(dev_file, \"w\")\n",
        "    ft = open(test_file, \"w\")\n",
        "         \n",
        "    for path_dict in dir:\n",
        "        print(\"Analizzo la cartella \" + str(path_dict))\n",
        "        # tutti i file nella cartella\n",
        "        dir_dict = os.listdir(path_to_prep_files + \"/\" + str(path_dict))\n",
        "        count = 0\n",
        "        \n",
        "        len_dir_dict = int(len(dir_dict)/4)\n",
        "        #1/10 dei dati\n",
        "        divis = 10\n",
        "        len_dir_dict = int(len_dir_dict/divis)\n",
        "        cnt_of_dir = 0\n",
        "        \n",
        "        for file in dir_dict:\n",
        "            if(count < len_dir_dict):\n",
        "              cnt_of_dir += 1\n",
        "              if file.split(\".\")[1] == \"WAV\":\n",
        "                p = path_to_prep_files + \"/\" + str(path_dict) + \"/\" + file\n",
        "                f = Sndfile(p, 'r')\n",
        "                frames = f.nframes\n",
        "                samplerate = f.samplerate\n",
        "                data = f.read_frames(frames)\n",
        "                data = np.asarray(data)\n",
        "                #print(data.shape)\n",
        "                #calc mfcc\n",
        "                feat_raw,energy = sf.fbank(data, samplerate,winlen,winstep, nfilt=numfilt)\n",
        "                feat = np.log(feat_raw)\n",
        "                feat = sf.dct(feat, type=2, axis=1, norm='ortho')[:,:numcep]\n",
        "                feat = sf.lifter(feat,L=22)\n",
        "                feat = np.asarray(feat)\n",
        "                #calc log energy\n",
        "                log_energy = np.log(energy) #np.log( np.sum(feat_raw**2, axis=1) )\n",
        "                log_energy = log_energy.reshape([log_energy.shape[0],1])\n",
        "                mat = ( feat - np.mean(feat, axis=0) ) / (0.5 * np.std(feat, axis=0))\n",
        "                mat = np.concatenate((mat, log_energy), axis=1)\n",
        "                #calc first order derivatives\n",
        "                if grad >= 1:\n",
        "                    gradf = np.gradient(mat)[0]\n",
        "                    mat = np.concatenate((mat, gradf), axis=1)\n",
        "                #calc second order derivatives\n",
        "                if grad == 2:\n",
        "                    grad2f = np.gradient(gradf)[0]\n",
        "                    mat = np.concatenate((mat, grad2f), axis=1)\n",
        "\n",
        "                #file_to_create = path_to_quats + \"/\" + file.split(\".\")[0] + \"_processed.data\"\n",
        "                # ff = open(file_to_create, \"w\")\n",
        "\n",
        "                \"\"\"\n",
        "                ff = open(train_file, \"w\")\n",
        "                fd = open(dev_file, \"w\")\n",
        "                ft = open(test_file, \"w\")\n",
        "                \"\"\"\n",
        "\n",
        "                n = 1\n",
        "                item = 0\n",
        "                print(\"Creo il quaternione\")\n",
        "                # quats_dict = make_quaternion(mat)\n",
        "                quats = make_quaternion(mat)\n",
        "                print('Appendo la classe del dialetto al quaternione')\n",
        "                dictionary ='    ' + dict_list[path_dict]\n",
        "                # quats_dict.append(dictionary)\n",
        "                #len_dir = (len(dir_dict))/16\n",
        "                len_dir = (len_dir_dict)\n",
        "\n",
        "                quats_length = len(quats)\n",
        "                count += 1\n",
        "                print('Quantita file nella cartella ' + path_dict + ': ' + str(len_dir) + ' '+ str(count))\n",
        "                if count > ((len_dir*90)/100):\n",
        "                  print(\"Creo DEV_FILE \"+ str(count))\n",
        "                  while (item < quats_length):\n",
        "                      if item == N_SPLIT * n:\n",
        "                          fd.write(dictionary)\n",
        "                          fd.write(\"\\n\")\n",
        "                          n = n + 1\n",
        "                      quat = quats[item]\n",
        "                      for i in range(len(quat)):\n",
        "                          if i == 3:\n",
        "                              fd.write(str(quat[i]) + \" \")\n",
        "                          else:\n",
        "                              fd.write(str(quat[i]) + \",\")\n",
        "                          item = item + 1\n",
        "                  x = int((n*N_SPLIT) - quats_length)\n",
        "                  for i in range(x):\n",
        "                      if i < x-1:\n",
        "                          fd.write(\"0,0,0,0 \")\n",
        "                      else:\n",
        "                          fd.write(\"0,0,0,0\")\n",
        "                elif count>((len_dir*70)/100):\n",
        "                  print(\"Creo TEST_FILE \" + str(count))\n",
        "                  while (item < quats_length):\n",
        "                      if item == N_SPLIT * n:\n",
        "                          ft.write(dictionary)\n",
        "                          ft.write(\"\\n\")\n",
        "                          n = n + 1\n",
        "                      quat = quats[item]\n",
        "                      for i in range(len(quat)):\n",
        "                          if i == 3:\n",
        "                              ft.write(str(quat[i]) + \" \")\n",
        "                          else:\n",
        "                              ft.write(str(quat[i]) + \",\")\n",
        "                      item = item + 1\n",
        "                  x = int((n*N_SPLIT) - quats_length)\n",
        "                  for i in range(x):\n",
        "                      if i < x-1:\n",
        "                          ft.write(\"0,0,0,0 \")\n",
        "                      else:\n",
        "                          ft.write(\"0,0,0,0\")\n",
        "                else:\n",
        "                  print(\"Creo TRAIN_FILE \"+ str(count))\n",
        "                  while (item < quats_length):\n",
        "                      if item == N_SPLIT * n:\n",
        "                          ff.write(dictionary)\n",
        "                          ff.write(\"\\n\")\n",
        "                          n = n + 1\n",
        "                      quat = quats[item]\n",
        "                      for i in range(len(quat)):\n",
        "                          if i == 3:\n",
        "                              ff.write(str(quat[i]) + \" \")\n",
        "                          else:\n",
        "                              ff.write(str(quat[i]) + \",\")\n",
        "                      item = item + 1\n",
        "\n",
        "                  x = int((n*N_SPLIT) - quats_length)\n",
        "                  for i in range(x):\n",
        "                      if i < x-1:\n",
        "                          ff.write(\"0,0,0,0 \")\n",
        "                      else:\n",
        "                          ff.write(\"0,0,0,0\")\n",
        "    #count = 0\n",
        "    ff.close()\n",
        "    ft.close()\n",
        "    fd.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsT5K7OKIuXw",
        "colab_type": "text"
      },
      "source": [
        "# LAST CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pgUlaN51RNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################### SPERO LULTIMO CODICE\n",
        "#!rm -r files_for_neural_Lom/\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from scikits.audiolab import Sndfile\n",
        "import python_speech_features as sf\n",
        "\n",
        "dict_list = {'DR1': \"1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR2': \"0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR3': \"0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR4': \"0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR5': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0 0,0,0,0\", \n",
        "            'DR6': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0 0,0,0,0\", \n",
        "            'DR7': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1 0,0,0,0\", \n",
        "            'DR8': \"0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 0,0,0,0 1,1,1,1\" \n",
        "            }\n",
        "dirlist = ['DR1', 'DR2', 'DR3', 'DR4', 'DR5', 'DR6', 'DR7', 'DR8']\n",
        "\n",
        "# creazione dei quaternioni appesi alla lista final_quat\n",
        "def make_quaternion(mat):\n",
        "\t#print(mat.shape)\n",
        "\tres = []\n",
        "\tfor row in range(len(mat)):\n",
        "\t\tfor j in range(41):\n",
        "\t\t\tquat = [0,mat[row][j],mat[row][j+41],mat[row][j+82]]\n",
        "\t\t\tres.append(quat)\n",
        "\treturn res\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ####################################\n",
        "    # pre process parameters    \n",
        "\t\n",
        "    # Mel-Frequency Cepstrum Coefficients, default 12\n",
        "    numcep=40 #40\n",
        "\t\n",
        "    # the number of filters in the filterbank, default 26\n",
        "    numfilt = 40 #40\n",
        "\n",
        "\t# the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
        "    winlen = 0.025\n",
        "\t\n",
        "    # the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
        "    winstep = 0.01\n",
        "\t\n",
        "    # use  first or first+second order derivation\n",
        "    grad = 2\n",
        "\n",
        "\t#number of elements for each set of quaternions\n",
        "    N_SPLIT = 100\n",
        "    #./drive/My Drive/COLAB Neural/\n",
        "    #dir_name = \"Quaternion_\" + str(N_SPLIT) + \"_Lamush\"\n",
        "    dir_name = \"files_for_neural_Lom\"\n",
        "    tree = dir_name\n",
        "    \n",
        "    #tree = \"/home/franci/Desktop/NN/Quaternion-speech-recognition/\" + dir_name\n",
        "    \n",
        "    if os.path.isdir(tree):\n",
        "        shutil.rmtree(tree)\n",
        "    os.makedirs(dir_name)\n",
        "    path_to_quats = os.path.abspath(dir_name)\n",
        "\n",
        "    train_file = os.path.join(path_to_quats,\"TRAIN_process\" + \".data\")\n",
        "    dev_file = os.path.join(path_to_quats,\"DEV_process\" + \".data\")\n",
        "    test_file = os.path.join(path_to_quats,\"TEST_process\" + \".data\")\n",
        "\n",
        "    if os.path.isfile(train_file):\n",
        "        os.remove(train_file)\n",
        "    if os.path.isfile(dev_file):\n",
        "        os.remove(dev_file)\n",
        "    if os.path.isfile(test_file):\n",
        "        os.remove(test_file)\n",
        "    \n",
        "    #count = 0 \n",
        "    path_to_prep_files = os.path.abspath(\"./drive/My Drive/COLAB Neural/preprocessed_files_with_dict/\")\n",
        "    \n",
        "#     path_to_prep_files = os.path.abspath(\"preprocessed_files_with_dict/\")\n",
        "    dir = os.listdir(path_to_prep_files)\n",
        "    \n",
        "    ff = open(train_file, \"a\")\n",
        "    fd = open(dev_file, \"a\")\n",
        "    ft = open(test_file, \"a\")\n",
        "         \n",
        "    for path_dict in dir:\n",
        "        print(\"Analizzo la cartella \" + str(path_dict))\n",
        "        # tutti i file nella cartella\n",
        "        dir_dict = os.listdir(path_to_prep_files + \"/\" + str(path_dict))\n",
        "        count = 0\n",
        "        \n",
        "        len_dir_dict = int(len(dir_dict)/4)\n",
        "        #1/3 dei dati\n",
        "        divis = 1\n",
        "        len_dir_dict = int(len_dir_dict/divis)\n",
        "        cnt_of_dir = 0\n",
        "        \n",
        "        for file in dir_dict:\n",
        "            if(count < len_dir_dict):\n",
        "              cnt_of_dir += 1\n",
        "              if file.split(\".\")[1] == \"WAV\":\n",
        "                p = path_to_prep_files + \"/\" + str(path_dict) + \"/\" + file\n",
        "                f = Sndfile(p, 'r')\n",
        "                frames = f.nframes\n",
        "                samplerate = f.samplerate\n",
        "                data = f.read_frames(frames)\n",
        "                data = np.asarray(data)\n",
        "                #print(data.shape)\n",
        "                #calc mfcc\n",
        "                feat_raw,energy = sf.fbank(data, samplerate,winlen,winstep, nfilt=numfilt)\n",
        "                feat = np.log(feat_raw)\n",
        "                feat = sf.dct(feat, type=2, axis=1, norm='ortho')[:,:numcep]\n",
        "                feat = sf.lifter(feat,L=22)\n",
        "                feat = np.asarray(feat)\n",
        "                #calc log energy\n",
        "                log_energy = np.log(energy) #np.log( np.sum(feat_raw**2, axis=1) )\n",
        "                log_energy = log_energy.reshape([log_energy.shape[0],1])\n",
        "                mat = ( feat - np.mean(feat, axis=0) ) / (0.5 * np.std(feat, axis=0))\n",
        "                mat = np.concatenate((mat, log_energy), axis=1)\n",
        "                #calc first order derivatives\n",
        "                if grad >= 1:\n",
        "                    gradf = np.gradient(mat)[0]\n",
        "                    mat = np.concatenate((mat, gradf), axis=1)\n",
        "                #calc second order derivatives\n",
        "                if grad == 2:\n",
        "                    grad2f = np.gradient(gradf)[0]\n",
        "                    mat = np.concatenate((mat, grad2f), axis=1)\n",
        "\n",
        "                #file_to_create = path_to_quats + \"/\" + file.split(\".\")[0] + \"_processed.data\"\n",
        "                # ff = open(file_to_create, \"w\")\n",
        "\n",
        "                \"\"\"\n",
        "                ff = open(train_file, \"w\")\n",
        "                fd = open(dev_file, \"w\")\n",
        "                ft = open(test_file, \"w\")\n",
        "                \"\"\"\n",
        "\n",
        "                n = 1\n",
        "                item = 0\n",
        "                row = 0\n",
        "\n",
        "                print(\"Creo il quaternione\")\n",
        "                # quats_dict = make_quaternion(mat)\n",
        "                quats = make_quaternion(mat)\n",
        "                print('Appendo la classe del dialetto al quaternione')\n",
        "                dictionary ='    ' + dict_list[path_dict] + '\\n'\n",
        "                # quats_dict.append(dictionary)\n",
        "                #len_dir = (len(dir_dict))/16\n",
        "                len_dir = (len_dir_dict)\n",
        "\n",
        "                quats_length = len(quats)\n",
        "                count += 1\n",
        "                print('Quantita file nella cartella ' + path_dict + ': ' + str(len_dir) + ' '+ str(count))\n",
        "                if count > ((len_dir*80)/100):\n",
        "                  print(\"Creo DEV_FILE \"+ str(count))\n",
        "                  while (item < quats_length):\n",
        "                    quat = quats[item]\n",
        "                      # I means i start to write in a new row\n",
        "                    if item == (row * N_SPLIT):\n",
        "                        fd.write(str(quat[0]))\n",
        "                        row = row + 1\n",
        "                    else:\n",
        "                        fd.write(\" \" + str(quat[0]))\n",
        "\n",
        "                    for i in range(1, len(quat)):\n",
        "                        fd.write(\",\" + str(quat[i]))\n",
        "\n",
        "                    if ( (item+1) == (N_SPLIT * row) ):\n",
        "                        fd.write(dictionary)\n",
        "                        #row = row + 1                    \n",
        "                    item = item + 1\n",
        "                  x = int((row * N_SPLIT) - quats_length)\n",
        "                  if x > 0:\n",
        "                    for i in range(x):\n",
        "                        fd.write(\" 0,0,0,0\")\n",
        "                    fd.write(dictionary)\n",
        "\n",
        "                elif count>((len_dir*70)/100):\n",
        "                  print(\"Creo TEST_FILE \" + str(count))\n",
        "                  while (item < quats_length):\n",
        "                    quat = quats[item]\n",
        "                      # I means i start to write in a new row\n",
        "                    if item == (row * N_SPLIT):\n",
        "                        ft.write(str(quat[0]))\n",
        "                        row = row + 1\n",
        "                    else:\n",
        "                        ft.write(\" \" + str(quat[0]))\n",
        "\n",
        "                    for i in range(1, len(quat)):\n",
        "                        ft.write(\",\" + str(quat[i]))\n",
        "\n",
        "                    if ( (item+1) == (N_SPLIT * row) ):\n",
        "                        ft.write(dictionary)\n",
        "                        #row = row + 1                    \n",
        "                    item = item + 1\n",
        "                  x = int((row * N_SPLIT) - quats_length)\n",
        "                  if x > 0:\n",
        "                    for i in range(x):\n",
        "                        ft.write(\" 0,0,0,0\")\n",
        "                    ft.write(dictionary)\n",
        "\n",
        "                else:\n",
        "                  print(\"Creo TRAIN_FILE \"+ str(count))\n",
        "                  while (item < quats_length):\n",
        "                    quat = quats[item]\n",
        "                    # I means i start to write in a new row\n",
        "                    if item == (row * N_SPLIT):\n",
        "                        ff.write(str(quat[0]))\n",
        "                        row = row + 1\n",
        "                    else:\n",
        "                        ff.write(\" \" + str(quat[0]))\n",
        "\n",
        "                    for i in range(1, len(quat)):\n",
        "                        ff.write(\",\" + str(quat[i]))\n",
        "\n",
        "                    if ( (item+1) == (N_SPLIT * row) ):\n",
        "                        ff.write(dictionary)\n",
        "                        #row = row + 1                    \n",
        "                    item = item + 1\n",
        "                  x = int((row * N_SPLIT) - quats_length)\n",
        "                  if x > 0:\n",
        "                    for i in range(x):\n",
        "                        ff.write(\" 0,0,0,0\")\n",
        "                    ff.write(dictionary)\n",
        "    #count = 0\n",
        "    ff.close()\n",
        "    ft.close()\n",
        "    fd.close()\n",
        "    \n",
        "# !zip -r files_for_neural_Lom250.zip files_for_neural_Lom && cp files_for_neural_Lom250_50.zip /content/drive/My\\ Drive/COLAB\\ Neural/\n",
        "!zip -r files_for_neural_Lom100_final.zip files_for_neural_Lom && cp files_for_neural_Lom100_final.zip /content/drive/My\\ Drive/COLAB\\ Neural/\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJSXotIppMMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r preprocessed_files_with_dict/.DS_Store"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDAX554x5nw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r files_for_neural_Lom/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf1fLz6P_v7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !zip -r files_for_neural_Lom400.zip files_for_neural_Lom && cp files_for_neural_Lom400.zip /content/drive/My\\ Drive/COLAB\\ Neural/\n",
        "!cp files_for_neural_Lom250_a8060.zip /content/drive/My\\ Drive/COLAB\\ Neural/\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aheIlJI-HQAc",
        "colab_type": "code",
        "outputId": "5416abb0-1d9a-4453-c04e-b91e6885eaea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip file_train_colab250.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open file_train_colab250.zip, file_train_colab250.zip.zip or file_train_colab250.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER5aNmxkc2lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm 'content/example_model_Lom.py'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntkruE9CijbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}